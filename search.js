window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "Test_automation", "modulename": "Test_automation", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "Test_automation.Utils", "modulename": "Test_automation", "qualname": "Utils", "kind": "class", "doc": "<p></p>\n"}, {"fullname": "Test_automation.Utils.__init__", "modulename": "Test_automation", "qualname": "Utils.__init__", "kind": "function", "doc": "<p>Initializes the class with the given storage name, scope, and key.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'storage_name' (str): The name of the storage.\n\n- 'scope' (str, optional): The scope of the storage.\n\n- 'key' (str, optional): The key for the storage.\n</code></pre>\n\n<p>Returns:\n    None.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">storage_name</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">scope</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">key</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span></span>)</span>"}, {"fullname": "Test_automation.Utils.storage_name", "modulename": "Test_automation", "qualname": "Utils.storage_name", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;&#x27;"}, {"fullname": "Test_automation.Utils.scope", "modulename": "Test_automation", "qualname": "Utils.scope", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;&#x27;"}, {"fullname": "Test_automation.Utils.key", "modulename": "Test_automation", "qualname": "Utils.key", "kind": "variable", "doc": "<p></p>\n", "default_value": "&#x27;&#x27;"}, {"fullname": "Test_automation.Utils.connect_storage", "modulename": "Test_automation", "qualname": "Utils.connect_storage", "kind": "function", "doc": "<p>Connects to the storage using the given scope and key.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- None.\n</code></pre>\n\n<p>Returns:\n    None. Sets the configuration for the Azure Data Lake Storage Gen2 account.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.new_df", "modulename": "Test_automation", "qualname": "Utils.new_df", "kind": "function", "doc": "<p>Tests the creation of a new dataframe by comparing the created dataframe and its schema to an expected dataframe and an expected schema.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- new_df (DataFrame): The newly created DataFrame. \n\n- expected_df (DataFrame): The expected DataFrame for comparison.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the dataframes or schemas do not match.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">new_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">expected_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.new_col", "modulename": "Test_automation", "qualname": "Utils.new_col", "kind": "function", "doc": "<p>Tests the creation of a new column in a dataframe by comparing the final dataframe to the initial dataframe.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'new_col' (str): The name of the newly created column.\n\n- 'expected_type_new_col' (type): The expected data type of the new column.\n\n- 'expected_nullable' (bool): The expected nullable property of the new column.\n\n- 'initial_df' (DataFrame): The initial DataFrame before the new column is added.\n\n- 'final_df' (DataFrame): The final DataFrame after the new column is added.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the new column or its properties do not match the expectations.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">new_col</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">expected_type_new_col</span><span class=\"p\">:</span> <span class=\"nb\">type</span>,</span><span class=\"param\">\t<span class=\"n\">expected_nullable</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">initial_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">final_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.renamed_col", "modulename": "Test_automation", "qualname": "Utils.renamed_col", "kind": "function", "doc": "<p>Tests the renaming of columns in a dataframe by comparing the renamed dataframe and its schema to an expected dataframe.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'renamed_df' (DataFrame): The DataFrame after the columns have been renamed.\n\n- 'expected_df' (DataFrame): The expected DataFrame for comparison.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the dataframes or schemas do not match the expectations.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">renamed_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">expected_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.dropped_col", "modulename": "Test_automation", "qualname": "Utils.dropped_col", "kind": "function", "doc": "<p>Tests the dropping of columns in a dataframe by comparing the dataframe after columns have been dropped to an expected dataframe.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'dropped_df' (DataFrame): The DataFrame after the columns have been dropped.\n\n- 'expected_df' (DataFrame): The expected DataFrame for comparison.\n\n- 'dropped_col' (list): The list of columns that have been dropped.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the dataframes do not match or if the dropped columns still exist in the dataframe.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">dropped_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">expected_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">dropped_col</span><span class=\"p\">:</span> <span class=\"nb\">list</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.conversion_type", "modulename": "Test_automation", "qualname": "Utils.conversion_type", "kind": "function", "doc": "<p>Tests the conversion of a column's data type in a dataframe.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'convert_df' (DataFrame): The DataFrame after the column's data type has been converted.\n\n- 'convert_col' (str): The name of the column whose data type has been converted.\n\n- 'expected_type' (type): The expected data type of the converted column.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the data type of the converted column does not match the expected data type.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">convert_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">convert_col</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">expected_type</span><span class=\"p\">:</span> <span class=\"nb\">type</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.csv_to_df", "modulename": "Test_automation", "qualname": "Utils.csv_to_df", "kind": "function", "doc": "<p>Converts a CSV file to a DataFrame.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'file_path' (str): The path to the CSV file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'csv'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    'expected_df' (DataFrame): The DataFrame created from the CSV file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.xlsx_to_df", "modulename": "Test_automation", "qualname": "Utils.xlsx_to_df", "kind": "function", "doc": "<p>Converts an XLSX file to a DataFrame.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'file_path' (str): The path to the XLSX file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'xlsx'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    'expected_df' (DataFrame): The DataFrame created from the XLSX file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.txt_to_df", "modulename": "Test_automation", "qualname": "Utils.txt_to_df", "kind": "function", "doc": "<p>Converts a TXT file to a DataFrame.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'file_path' (str): The path to the TXT file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'txt'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    'expected_df' (DataFrame): The DataFrame created from the TXT file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.json_to_df", "modulename": "Test_automation", "qualname": "Utils.json_to_df", "kind": "function", "doc": "<p>Converts a JSON file to a DataFrame.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'file_path' (str): The path to the JSON file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'json'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    'expected_df' (DataFrame): The DataFrame created from the JSON file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.parquet_to_df", "modulename": "Test_automation", "qualname": "Utils.parquet_to_df", "kind": "function", "doc": "<p>Converts a Parquet file to a DataFrame.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'file_path' (str): The path to the Parquet file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'parquet'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    'expected_df' (DataFrame): The DataFrame created from the Parquet file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.function_df_input", "modulename": "Test_automation", "qualname": "Utils.function_df_input", "kind": "function", "doc": "<p>Applies a given function to a set of parameters and tests the resulting DataFrame by comparing it to an expected DataFrame.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'expected_df' (DataFrame): The expected DataFrame for comparison.\n\n- 'function' (callable): The function to be tested.\n\n- 'list_func_param' (list): The list of parameters to be passed to the function.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the DataFrame returned by the function does not match the expected DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">expected_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">function</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"nb\">callable</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">list_func_param</span><span class=\"p\">:</span> <span class=\"nb\">list</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.file_result_df_input", "modulename": "Test_automation", "qualname": "Utils.file_result_df_input", "kind": "function", "doc": "<p>Reads a DataFrame from a specified file path using the given file type and options.\nCompares the resulting DataFrame with an expected DataFrame for equality.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'expected_df' (DataFrame): The expected DataFrame for comparison.\n\n- 'file_path' (str): The path to the file to be read.\n\n- 'file_type' (str): The format of the file (e.g., 'parquet', 'csv', etc.).\n\n- 'options' (dict, optional): Additional options for reading the file (default: {}).\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the DataFrame read from the file does not match the expected DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">expected_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.function_csv_input", "modulename": "Test_automation", "qualname": "Utils.function_csv_input", "kind": "function", "doc": "<p>Applies a given function to a set of parameters and tests the resulting DataFrame by comparing it to an expected DataFrame created from a CSV file.</p>\n\n<p>Parameters:\n    - 'function' (callable): The function to be tested.</p>\n\n<pre><code>- 'list_func_param' (list): The list of parameters to be passed to the function.\n\n- 'file_path' (str): The path to the file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'csv'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the DataFrame returned by the function does not match the expected DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">function</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"nb\">callable</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">list_func_param</span><span class=\"p\">:</span> <span class=\"nb\">list</span>,</span><span class=\"param\">\t<span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.function_txt_input", "modulename": "Test_automation", "qualname": "Utils.function_txt_input", "kind": "function", "doc": "<p>Applies a given function to a set of parameters and tests the resulting DataFrame by comparing it to an expected DataFrame created from a TXT file.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'function' (callable): The function to be tested.\n\n- 'list_func_param' (list): The list of parameters to be passed to the function.\n\n- 'file_path' (str): The path to the file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'txt'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the DataFrame returned by the function does not match the expected DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">function</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"nb\">callable</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">list_func_param</span><span class=\"p\">:</span> <span class=\"nb\">list</span>,</span><span class=\"param\">\t<span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.function_xlsx_input", "modulename": "Test_automation", "qualname": "Utils.function_xlsx_input", "kind": "function", "doc": "<p>Applies a given function to a set of parameters and tests the resulting DataFrame by comparing it to an expected DataFrame created from an XLSX file.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'function' (callable): The function to be tested.\n\n- 'list_func_param' (list): The list of parameters to be passed to the function.\n\n- 'file_path' (str): The path to the file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'xlsx'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the DataFrame returned by the function does not match the expected DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">function</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"nb\">callable</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">list_func_param</span><span class=\"p\">:</span> <span class=\"nb\">list</span>,</span><span class=\"param\">\t<span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.function_json_input", "modulename": "Test_automation", "qualname": "Utils.function_json_input", "kind": "function", "doc": "<p>Applies a given function to a set of parameters and tests the resulting DataFrame by comparing it to an expected DataFrame created from a JSON file.</p>\n\n<p>Parameters:\n    - 'function' (callable): The function to be tested.</p>\n\n<pre><code>- 'list_func_param' (list): The list of parameters to be passed to the function.\n\n- 'file_path' (str): The path to the file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'json'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the DataFrame returned by the function does not match the expected DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">function</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"nb\">callable</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">list_func_param</span><span class=\"p\">:</span> <span class=\"nb\">list</span>,</span><span class=\"param\">\t<span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.function_parquet_input", "modulename": "Test_automation", "qualname": "Utils.function_parquet_input", "kind": "function", "doc": "<p>Applies a given function to a set of parameters and tests the resulting DataFrame by comparing it to an expected DataFrame created from a Parquet file.</p>\n\n<p>Parameters:\n    - 'function' (callable): The function to be tested.</p>\n\n<pre><code>- 'list_func_param' (list): The list of parameters to be passed to the function.\n\n- 'file_path' (str): The path to the file.\n\n- 'file_type' (str): The type of the file. In this case, it should be 'parquet'.\n\n- 'options' (dict): Options for reading the file.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the DataFrame returned by the function does not match the expected DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">function</span><span class=\"p\">:</span> <span class=\"o\">&lt;</span><span class=\"n\">built</span><span class=\"o\">-</span><span class=\"ow\">in</span> <span class=\"n\">function</span> <span class=\"nb\">callable</span><span class=\"o\">&gt;</span>,</span><span class=\"param\">\t<span class=\"n\">list_func_param</span><span class=\"p\">:</span> <span class=\"nb\">list</span>,</span><span class=\"param\">\t<span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">file_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">options</span><span class=\"p\">:</span> <span class=\"nb\">dict</span> <span class=\"o\">=</span> <span class=\"p\">{}</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.duplicates_df", "modulename": "Test_automation", "qualname": "Utils.duplicates_df", "kind": "function", "doc": "<p>Checks if a DataFrame has duplicate rows.</p>\n\n<p>This function counts the total number of rows and the number of distinct rows in the DataFrame. \nIf the two counts are not equal, it means there are duplicate rows in the DataFrame, and the function raises an AssertionError.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'df_to_test' (DataFrame): The DataFrame to be checked for duplicates.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the DataFrame has duplicate values.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">df_to_test</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.duplicates_col", "modulename": "Test_automation", "qualname": "Utils.duplicates_col", "kind": "function", "doc": "<p>Checks if a column in a DataFrame has duplicate values.</p>\n\n<p>This function counts the total number of values and the number of distinct values in the specified column of the DataFrame. \nIf the two counts are not equal, it means there are duplicate values in the column, and the function raises an AssertionError.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'df_to_test' (DataFrame): The DataFrame to be checked for duplicates.\n\n- 'col_name' (str): The name of the column to be checked for duplicates.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the column in the DataFrame has duplicate values.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">df_to_test</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>, </span><span class=\"param\"><span class=\"n\">col_name</span><span class=\"p\">:</span> <span class=\"nb\">list</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.filter_by_condition", "modulename": "Test_automation", "qualname": "Utils.filter_by_condition", "kind": "function", "doc": "<p>This function filters a DataFrame based on a provided condition and then checks the filtered DataFrame against an expected DataFrame.</p>\n\n<p>It applies a filter to the DataFrame based on the provided condition. The filtered DataFrame is then checked against the expected DataFrame using the <code>filter_by_df</code> function.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'filter_df' (DataFrame): The DataFrame to be filtered.\n\n- 'condition': The condition to be used for filtering the DataFrame.\n\n- 'expected_df' (DataFrame): The expected DataFrame after filtering.\n</code></pre>\n\n<p>Returns:\n    None. The function will raise an AssertionError if the filtered DataFrame does not match the expected DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">filter_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">condition</span>,</span><span class=\"param\">\t<span class=\"n\">expected_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.filter_by_df", "modulename": "Test_automation", "qualname": "Utils.filter_by_df", "kind": "function", "doc": "<p>This function checks if a filtered DataFrame matches an expected DataFrame.</p>\n\n<p>It applies a filter to the DataFrame based on the provided condition. Then, it checks if any rows from the filtered DataFrame exist in the unfiltered DataFrame. If they do, an AssertionError is raised. Finally, it checks if the filtered DataFrame matches the expected DataFrame using the <code>assertDataFrameEqual</code> function.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'filter_df' (DataFrame) : The DataFrame to be filtered.\n\n- 'expected_df' (DataFrame) : The expected DataFrame after filtering.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the filtered DataFrame does not match the expected DataFrame or if any rows from the filtered DataFrame exist in the unfiltered DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">filter_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">expected_df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Test_automation.Utils.write_df", "modulename": "Test_automation", "qualname": "Utils.write_df", "kind": "function", "doc": "<p>Checks if a file exists at the specified path.</p>\n\n<p>This function splits the file path to get its type, then checks if a file exists at the given location. If the check fails, the function raises an AssertionError.</p>\n\n<p>Parameters:</p>\n\n<pre><code>- 'file_path' (str): The file path.\n</code></pre>\n\n<p>Returns:\n    None. Raises an AssertionError if the file does not exist at the specified path.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">file_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();